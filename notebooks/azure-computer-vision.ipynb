{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0a41ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OECEDENT\n",
      "DABA\n",
      "AYEHUSH\n",
      "H\n",
      "(FEMALE)\n",
      "ACE\n",
      "68\n",
      "Lor\n",
      "•\n",
      "•\n",
      "ROW\n",
      "INTERMENT\n",
      "NO\n",
      "NA\n",
      "OATE\n",
      "OF\n",
      "FUNERAL\n",
      "HOUE\n",
      "SECTION\n",
      "BLOCK\n",
      "VETERAN\n",
      "NO\n",
      "GATLINC\n",
      "LOT\n",
      "OWNER\n",
      "NEXT\n",
      "OF\n",
      "XIN\n",
      "TAT)F.SSF,\n",
      "DABA\n",
      "ADDRESS\n",
      "7217\n",
      "225\n",
      "ROW\n",
      "2\n",
      "6\n",
      "CR\n",
      "BOX\n",
      "HELAJ'ON\n",
      "RELATION\n",
      "CHICAGO,\n",
      "IL\n",
      "60617\n",
      "MARKER\n",
      "HUSBAND\n",
      "702-292-0263\n",
      "DEALE*\n",
      "C)\n",
      "SINGLE\n",
      "ÜCOMPANION\n",
      "D\n",
      "MONUMENT\n",
      "OIN\n",
      "ÜOUT\n",
      "D\n",
      "GRANITE\n",
      "DATE\n",
      "SET\n",
      "O\n",
      "BRONZE/GRANITE\n",
      "D\n",
      "VETERAN\n",
      "EMAIL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "# If you are using a Jupyter Notebook, uncomment the following line.\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Add your Computer Vision subscription key and endpoint to your environment variables.\n",
    "os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY'] = \"2d2bf7809b9c4d94866d6ca02752977f\"\n",
    "os.environ['COMPUTER_VISION_ENDPOINT'] = \"https://eai6020.cognitiveservices.azure.com/\"\n",
    "if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
    "    subscription_key = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
    "else:\n",
    "    print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
    "    sys.exit()\n",
    "\n",
    "if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
    "    endpoint = os.environ['COMPUTER_VISION_ENDPOINT']\n",
    "\n",
    "ocr_url = endpoint + \"vision/v3.1/ocr\"\n",
    "\n",
    "image_path = \"../OneDrive_1_11-6-2019/iCard_021873_1_Daba_Ayehush_H.jpg\"\n",
    "# Read the image into a byte array\n",
    "image_data = open(image_path, \"rb\").read()\n",
    "# Set Content-Type to octet-stream\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key, 'Content-Type': 'application/octet-stream'}\n",
    "params = {'language': 'en', 'detectOrientation': 'true'}\n",
    "# put the byte array into your post request\n",
    "response = requests.post(ocr_url, headers=headers, params=params, data = image_data)\n",
    "\n",
    "response.raise_for_status()\n",
    "\n",
    "analysis = response.json()\n",
    "\n",
    "# Extract the word bounding boxes and text.\n",
    "line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "word_infos = []\n",
    "for line in line_infos:\n",
    "    for word_metadata in line:\n",
    "        for word_info in word_metadata[\"words\"]:\n",
    "            word_infos.append(word_info)\n",
    "word_infos\n",
    "\n",
    "full_text = \"\"\n",
    "for word in word_infos:\n",
    "    full_text += f\"{word['text']}\\n\"\n",
    "    \n",
    "\n",
    "# # Display the image and overlay it with the extracted text.\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# image = Image.open(image_path)\n",
    "# ax = plt.imshow(image, alpha=0.5)\n",
    "# for word in word_infos:\n",
    "#     bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "#     text = word[\"text\"]\n",
    "#     origin = (bbox[0], bbox[1])\n",
    "#     patch = Rectangle(origin, bbox[2], bbox[3],\n",
    "#                       fill=False, linewidth=2, color='y')\n",
    "#     ax.axes.add_patch(patch)\n",
    "#     plt.text(origin[0], origin[1], text, fontsize=20, weight=\"bold\", va=\"top\")\n",
    "# plt.show()\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84cee680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iCard_021875_1_Daba_Shorro.jpg\n",
      "1 / 123 Processed\n",
      "iCard_021960_1.jpg\n",
      "2 / 123 Processed\n",
      "iCard_021912_1_Dahlberg_John.jpg\n",
      "3 / 123 Processed\n",
      "iCard_021894_1_Daehn_Herman_W.jpg\n",
      "4 / 123 Processed\n",
      "iCard_021936_1_Dahlstrom_Violet.jpg\n",
      "5 / 123 Processed\n",
      "iCard_021977_1_Daker_Raphael.jpg\n",
      "6 / 123 Processed\n",
      "iCard_021988_1_Dako_Martha.jpg\n",
      "7 / 123 Processed\n",
      "iCard_021906_1_Dagdigian_Robert.jpg\n",
      "8 / 123 Processed\n",
      "iCard_021927_1_Dahlstrom_Anna.jpg\n",
      "9 / 123 Processed\n",
      "iCard_021982_1_Dakin_Hannah_Lois.jpg\n",
      "10 / 123 Processed\n",
      "iCard_021895_1_Daemicke_George_F.jpg\n",
      "11 / 123 Processed\n",
      "iCard_021987_1_Dako_Caroline.uzn\n",
      "iCard_021908_1_Dagdigian.jpg\n",
      "12 / 123 Processed\n",
      "iCard_021914_1_Dahleen_Robert_Charles.jpg\n",
      "13 / 123 Processed\n",
      "iCard_021911_1_Daggs_Ernest.jpg\n",
      "14 / 123 Processed\n",
      "iCard_021917_1_Dahlem_Roy_A.jpg\n",
      "15 / 123 Processed\n",
      "iCard_021942_1_Dahne_Richard.jpg\n",
      "16 / 123 Processed\n",
      "iCard_021975_1_Daker_Laura.jpg\n",
      "17 / 123 Processed\n",
      "iCard_021934_1_Dahlstrom_Ragnar_F.jpg\n",
      "18 / 123 Processed\n",
      "iCard_021976_1_Daker_Ralph.jpg\n",
      "19 / 123 Processed\n",
      "iCard_021955_1_Dailey_Mary.jpg\n",
      "20 / 123 Processed\n",
      "iCard_021921_1_Dahlin_Anna_V.jpg\n",
      "21 / 123 Processed\n",
      ".DS_Store\n",
      "iCard_021896_1_Daemicke_Ernestine.jpg\n",
      "22 / 123 Processed\n",
      "iCard_021920_1_Dahlin_Anna_V.jpg\n",
      "23 / 123 Processed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7bb8a904d8aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mall_text_detections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_detection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "# If you are using a Jupyter Notebook, uncomment the following line.\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Add your Computer Vision subscription key and endpoint to your environment variables.\n",
    "os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY'] = \"2d2bf7809b9c4d94866d6ca02752977f\"\n",
    "os.environ['COMPUTER_VISION_ENDPOINT'] = \"https://eai6020.cognitiveservices.azure.com/\"\n",
    "if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
    "    subscription_key = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
    "else:\n",
    "    print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
    "    sys.exit()\n",
    "\n",
    "if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
    "    endpoint = os.environ['COMPUTER_VISION_ENDPOINT']\n",
    "\n",
    "ocr_url = endpoint + \"vision/v3.1/ocr\"\n",
    "\n",
    "all_text_detections = []\n",
    "files = os.listdir(\"../OneDrive_1_11-6-2019\")\n",
    "\n",
    "i = 1\n",
    "for filename in files:\n",
    "    print(filename)\n",
    "    if not os.path.isfile(f\"../OneDrive_1_11-6-2019/{filename}\"):\n",
    "        continue\n",
    "        \n",
    "    if not filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "        continue\n",
    "    image_path = f\"../OneDrive_1_11-6-2019/{filename}\"\n",
    "    # Read the image into a byte array\n",
    "    image_data = open(image_path, \"rb\").read()\n",
    "    # Set Content-Type to octet-stream\n",
    "    headers = {'Ocp-Apim-Subscription-Key': subscription_key, 'Content-Type': 'application/octet-stream'}\n",
    "    params = {'language': 'en', 'detectOrientation': 'true'}\n",
    "    # put the byte array into your post request\n",
    "    response = requests.post(ocr_url, headers=headers, params=params, data = image_data)\n",
    "\n",
    "    response.raise_for_status()\n",
    "\n",
    "    analysis = response.json()\n",
    "\n",
    "    # Extract the word bounding boxes and text.\n",
    "    line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "    word_infos = []\n",
    "    for line in line_infos:\n",
    "        for word_metadata in line:\n",
    "            for word_info in word_metadata[\"words\"]:\n",
    "                word_infos.append(word_info)\n",
    "    word_infos\n",
    "\n",
    "    full_text = \"\"\n",
    "    for word in word_infos:\n",
    "        full_text += f\"{word['text']}\\n\"\n",
    "    text_detection = {\n",
    "        \"filename\": filename,\n",
    "        \"text\": full_text\n",
    "    }\n",
    "    print(f\"{i} / {len(files)} Processed\")\n",
    "    i += 1\n",
    "    all_text_detections.append(text_detection)\n",
    "    time.sleep(4)\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(all_text_detections)\n",
    "\n",
    "df.to_csv(\"first_attempt_azure.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c95e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
